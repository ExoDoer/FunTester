# 记一次失败的爬虫

收到一天振奋人心的假新闻，导致我去找了公开信息网站定点药店的信息，虽然结果比较失败，过程还是挺欢乐的，记录下来又可以水一篇文章了。以下是原文：

---

页面搜索功能有限，我就做了一个爬虫，思路分了两步，先找药店名称的编号，再查药店的具体地址。

这里面只有773条网点信息，我顺手做了个爬虫，代码粗糙，十几分钟完成的，效果还可以。代码分享如下：

```Groovy

package com.fun

import com.fun.frame.Save
import com.fun.frame.httpclient.FanLibrary
import com.fun.utils.Regex
import com.fun.utils.WriteRead
import net.sf.json.JSONObject
import org.apache.http.client.methods.HttpGet
import org.apache.http.client.methods.HttpPost

class sd extends FanLibrary {

    static names = []

    public static void main(String[] args) {

        test2(1)
//        52.times {
//            test(it+1)
//        }
//        Save.saveStringList(names,"hospital")

        def line = WriteRead.readTxtFileByLine(LONG_Path + "hospital")
        line.each {
            def s = it.split(" ", 3)[1]
            output(s)
            it += test2(changeStringToInt(s))
            names << it
        }
        Save.saveStringList(names,"address.txt")

        testOver()
    }

    static def test(int i) {
        String url = "http://ybj.beijing.gov.cn/ddyy/ddyy2/list";

        HttpPost httpPost = getHttpPost(url, getJson("page=" + i));

        JSONObject response = getHttpResponse(httpPost);
        def all = response.getString("content").replaceAll("\\s", EMPTY)

        def infos = Regex.regexAll(all, "<tr>.*?</tr>")
        infos.remove(0)
        output(infos)
        output(infos.size())
        infos.each {x ->
            names << x.substring(4).replaceAll("<.*?>", SPACE_1)
        }
        output(names.size())
    }
    static def test2(int i) {
        String url = "http://ybj.beijing.gov.cn/ddyy/ddyy2/findByName?id="+i;

        HttpGet httpGet = getHttpGet(url);

        JSONObject response = getHttpResponse(httpGet);
        def all = response.getString("content").replaceAll("\\s", EMPTY)

        def infos = Regex.regexAll(all, "<tr>.*?</tr>")
//        infos.remove(0)
        output(infos)
//        output(infos.size())
        def address = EMPTY
        infos.each {x ->
//            names << x.substring(4).replaceAll("<.*?>", SPACE_1)
           address += x.substring(4).replaceAll("<.*?>", SPACE_1)
        }
        output(address)
        return address
    }
}
```

下面是两次爬虫的页面结构：

![](http://pic.automancloud.com/QQ20200204-094146.png)

![](http://pic.automancloud.com/QQ20200204-094121.png)

篇幅有限，我已经整理了Excel文档。需要的小伙伴添加微信索要。

![](http://pic.automancloud.com/WechatIMG24.jpeg)

---
* **郑重声明**：文章首发于公众号“FunTester”，禁止第三方（腾讯云除外）转载、发表。

## 技术类文章精选

- [Linux性能监控软件netdata中文汉化版](https://mp.weixin.qq.com/s/fdXtK-5WwKnxjLZdyg6-nA)
- [性能测试框架第三版](https://mp.weixin.qq.com/s/Mk3PoH7oJX7baFmbeLtl_w)
- [如何在Linux命令行界面愉快进行性能测试](https://mp.weixin.qq.com/s/fwGqBe1SpA2V0lPfAOd04Q)
- [图解HTTP脑图](https://mp.weixin.qq.com/s/100Vm8FVEuXs0x6rDGTipw)
- [将swagger文档自动变成测试代码](https://mp.weixin.qq.com/s/SY8mVenj0zMe5b47GS9VSQ)
 - [Selenium 4.0 Alpha更新日志](https://mp.weixin.qq.com/s/tU7sm-pcbpRNwDU9D3OVTQ)
- [Selenium 4.0 Alpha更新实践](https://mp.weixin.qq.com/s/yT9wpO5o5aWBUus494TIHw)
- [如何统一接口测试的功能、自动化和性能测试用例](https://mp.weixin.qq.com/s/1xqtXNVw7BdUa03nVcsMTg)

## 非技术文章精选

- [写给所有人的编程思维](https://mp.weixin.qq.com/s/Oj33UCnYfbUgzsBzEm2GPQ)
- [成为自动化测试的7种技能](https://mp.weixin.qq.com/s/e-HAGMO0JLR7VBBWLvk0dQ)
- [Web端自动化测试失败原因汇总](https://mp.weixin.qq.com/s/qzFth-Q9e8MTms1M8L5TyA)
- [测试人员常用借口](https://mp.weixin.qq.com/s/0k_Ciud2sOpRb5PPiVzECw)
- [API测试基础](https://mp.weixin.qq.com/s/bkbUEa9CF21xMYSlhPcULw)
- [API自动化测试指南](https://mp.weixin.qq.com/s/uy_Vn_ZVUEu3YAI1gW2T_A)
- [未来的QA测试工程师](https://mp.weixin.qq.com/s/ngL4sbEjZm7OFAyyWyQ3nQ)
- [JSON基础](https://mp.weixin.qq.com/s/tnQmAFfFbRloYp8J9TYurw)
- [2020年Tester自我提升](https://mp.weixin.qq.com/s/vuhUp85_6Sbg6ReAN3TTSQ)

![](https://mmbiz.qpic.cn/mmbiz_jpg/13eN86FKXzCMW6WN4Wch71qNtGQvxLRSGejZpr37OWa7CDYg5e4ZeanaGWuBgRAX3jicJNIhcyyZPXbKByXcl7w/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)